{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjKg47GBdXY9"
   },
   "source": [
    "# **Brain and Cognitive Society, IIT Kanpur**\n",
    "## **Introduction to Deep Learning Workshop**\n",
    "**This python notebook is an assingment on ML/DL**\n",
    "\n",
    "In this assingment you will solve a **regression** problem of predicting House prices using basic python libraries, and build a **neural network** for handwritten digit identification using **TensorFlow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSRalact4xj4"
   },
   "source": [
    "## **Linear Regression**\n",
    "We will use Linear regression for predicting house prices\n",
    "\n",
    "We are using a Kaggle dataset- https://www.kaggle.com/harlfoxem/housesalesprediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "J8MRCcJY2btt"
   },
   "outputs": [],
   "source": [
    "# Lets import required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MzAhMmE6UHE"
   },
   "source": [
    "### **Dataset Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LiWI-2py554R",
    "outputId": "4ea974b8-fe97-4fea-ce48-0bb4b7f3fe9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-06-05 21:59:40--  https://docs.google.com/uc?export=download&id=16x6-8Znn2T50zFwVvKlzsdN7Jd1hpjct\n",
      "Resolving docs.google.com (docs.google.com)... 142.250.200.238\n",
      "Connecting to docs.google.com (docs.google.com)|142.250.200.238|:443... connected.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://doc-14-3o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/hta5sah2dcmt2lt0od5mbtbunm7q9350/1685982525000/17346214133729595847/*/16x6-8Znn2T50zFwVvKlzsdN7Jd1hpjct?e=download&uuid=2cf2fcc5-4049-4553-b75a-d9093e8be4c4 [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2023-06-05 21:59:43--  https://doc-14-3o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/hta5sah2dcmt2lt0od5mbtbunm7q9350/1685982525000/17346214133729595847/*/16x6-8Znn2T50zFwVvKlzsdN7Jd1hpjct?e=download&uuid=2cf2fcc5-4049-4553-b75a-d9093e8be4c4\n",
      "Resolving doc-14-3o-docs.googleusercontent.com (doc-14-3o-docs.googleusercontent.com)... 142.250.200.225\n",
      "Connecting to doc-14-3o-docs.googleusercontent.com (doc-14-3o-docs.googleusercontent.com)|142.250.200.225|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2515206 (2.4M) [text/csv]\n",
      "Saving to: 'Linear_regression_dataset'\n",
      "\n",
      "Linear_regression_d 100%[===================>]   2.40M  1.56MB/s    in 1.5s    \n",
      "\n",
      "2023-06-05 21:59:47 (1.56 MB/s) - 'Linear_regression_dataset' saved [2515206/2515206]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute this cell for loading dataset in a pandas dataframe\n",
    "\n",
    "from IPython.display import clear_output\n",
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=16x6-8Znn2T50zFwVvKlzsdN7Jd1hpjct' -O Linear_regression_dataset\n",
    "\n",
    "data_df = pd.read_csv(\"Linear_regression_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "TAodxbYX7AKf",
    "outputId": "687f37dc-ebe7-4a4e-a48b-a4df72206414"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(No of rows, No of Columns) =  (21613, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets have a quick Look at dataset\n",
    "\n",
    "print(\"(No of rows, No of Columns) = \",data_df.shape)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsJaooGZ7pUV"
   },
   "source": [
    "So there are **19** features (of course we will not use id as feature :) ), and 1 variable to predict(price)\n",
    "\n",
    "But note that the **date** column contain strings so first we will remove T00.. part from it and than convert it to numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "FNFNf3jT7oxW",
    "outputId": "a3df8c82-3441-41ec-b08b-2021a07efb45"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id      date     price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
       "0  7129300520  20141013  221900.0         3       1.00         1180      5650   \n",
       "1  6414100192  20141209  538000.0         3       2.25         2570      7242   \n",
       "2  5631500400  20150225  180000.0         2       1.00          770     10000   \n",
       "3  2487200875  20141209  604000.0         4       3.00         1960      5000   \n",
       "4  1954400510  20150218  510000.0         3       2.00         1680      8080   \n",
       "\n",
       "   floors  waterfront  view  ...  grade  sqft_above  sqft_basement  yr_built  \\\n",
       "0     1.0           0     0  ...      7        1180              0      1955   \n",
       "1     2.0           0     0  ...      7        2170            400      1951   \n",
       "2     1.0           0     0  ...      6         770              0      1933   \n",
       "3     1.0           0     0  ...      7        1050            910      1965   \n",
       "4     1.0           0     0  ...      8        1680              0      1987   \n",
       "\n",
       "   yr_renovated  zipcode      lat     long  sqft_living15  sqft_lot15  \n",
       "0             0    98178  47.5112 -122.257           1340        5650  \n",
       "1          1991    98125  47.7210 -122.319           1690        7639  \n",
       "2             0    98028  47.7379 -122.233           2720        8062  \n",
       "3             0    98136  47.5208 -122.393           1360        5000  \n",
       "4             0    98074  47.6168 -122.045           1800        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['date'] = data_df['date'].str.replace('T000000','')                 # Remove T000000 part from data column. Hint: search about .str.replace() method. :) \n",
    "data_df['date'] = data_df['date'].astype(int)                  \n",
    "data_df2 = data_df.drop(['id'],axis = 1)\n",
    "data_array = np.array(data_df2)                                              # Create a numpy array which does not have \"id\" field\n",
    "assert (data_array.shape == (21613,20))\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsBZxZ4x-oBR"
   },
   "source": [
    "Now the next task is **normalization**.\n",
    "\n",
    "We will scale each column of dataset by x -> (x-u)/s\n",
    "\n",
    "where u is mean(x), and s is standard deviation of u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u7GZV-0T_zCy",
    "outputId": "95d93945-1a45-4853-d86d-18409aec6376"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21613, 20)\n"
     ]
    }
   ],
   "source": [
    "mean = np.array(data_array.mean(axis=0))                                # this should be an array, each entry should be mean of a column\n",
    "sd = np.array(data_array.std(axis=0))                                    # this should be an array, each entry should be standard deviation of a column\n",
    "\n",
    "data_array_norm = (data_array - mean)/sd\n",
    "\n",
    "print(data_array_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCQTrNIgAlPv"
   },
   "source": [
    "The last step is to make train and test dataset and to create seperate vector for price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dJyX5QOFBRg5",
    "outputId": "22469725-a668-457d-dbd9-a14a9f69eb81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18371, 19) (3242, 19) (18371,) (3242,)\n"
     ]
    }
   ],
   "source": [
    "labels = data_df['price']                                                                                                            # extract the price column from data\n",
    "\n",
    "x_array_norm = np.delete(data_array_norm,1,1)                                                                                                    # delete the price column from data_array_norm. Hint: use np.delete()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_array_norm,labels,test_size=0.15,random_state=42,shuffle=True)    # splitting data into test and train set.\n",
    "\n",
    "print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iAdW-22ZDcdU"
   },
   "source": [
    "### **Loss and gradient descent**\n",
    "We will use mean squared error(MSE) as loss\n",
    "\n",
    "Use the gradient descent algorithm which you learned from tutorials\n",
    "\n",
    "Your task is to complete the following functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ufoIQOpeEFQx"
   },
   "outputs": [],
   "source": [
    "def loss(y_pred,y_true):\n",
    "  \"\"\"\n",
    "  input:\n",
    "  y_pred = [array] predicted value of y\n",
    "  y_true = [array] ground truth\n",
    "  \n",
    "  output:\n",
    "  mse: [scalar] the MES loss\n",
    "  \"\"\"\n",
    "  mse = np.mean((y_true - y_pred)**2)                    # fill code here\n",
    "\n",
    "  return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "a6LogNz5E28X"
   },
   "outputs": [],
   "source": [
    "def y(x,a,b):\n",
    "  \"\"\"\n",
    "  This function should return predicted value of y = ax+b\n",
    "  input:\n",
    "  x: [array] the feature vector of shape (m,n)\n",
    "  a: [array] weights of shape (n,)\n",
    "  b: [scalar] bias\n",
    "  \n",
    "  output:\n",
    "  y_pred: [array] predicted value of y of shape (m,)\n",
    "  \"\"\"\n",
    "\n",
    "  m,n = x.shape\n",
    "  y_pred = np.dot(x, a) + b                   # fill code here\n",
    "\n",
    "  assert(y_pred.shape == (m,))\n",
    "  return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "lYnPROu8Gxwi"
   },
   "outputs": [],
   "source": [
    "def gradient(x,a,b,y_true):\n",
    "  \"\"\"\n",
    "  This function shoud return gradient of loss\n",
    "  input:\n",
    "  x: [array] the feature vector of shape (m,n)\n",
    "  a: [array] weights of shape (n,)\n",
    "  b: [scalar] bias\n",
    "  y_true: [array] ground truth of shape (m,)\n",
    "\n",
    "  output:\n",
    "  grad: [tuple] a tuple (derivative with respect to a[array of shape(n,)], derivative with respect to b[scalar])\n",
    "  \"\"\"\n",
    "  m,n = x.shape\n",
    "  yp = y(x,a,b)\n",
    "\n",
    "  da =  (2/m)* np.sum(np.multiply(x,(yp-y_true)[:,np.newaxis]),axis=0)           # write code to calculate derivative of loss with respect to a\n",
    "  db = (2/m) * np.sum((yp - y_true))              # write code to calculate derivative of loss with respect to b\n",
    "\n",
    "  assert(da.shape ==(n,))\n",
    "  return (da,db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "km_z3ojKKQdj"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(x,y_true,learning_rate=0.01,epochs = 10):\n",
    "  \"\"\"\n",
    "  This function perfroms gradient descent and minimizes loss\n",
    "  input:\n",
    "  x: [array] the feature vector of shape (m,n)\n",
    "  y_true: [array] ground truth of shape (m,)\n",
    "  \n",
    "  output:\n",
    "  loss: [array] of size (epochs,)\n",
    "  weights: [tuple] (a,b)\n",
    "  \"\"\"\n",
    "  m,n = x.shape\n",
    "  loss_mse = []                                 # initialize empty list to store loss\n",
    "  a = np.zeros((n,))                                 # initialize a- weights and b- bias\n",
    "  b = 0\n",
    "\n",
    "  for i in range(epochs):\n",
    "    # calculate derivative using gradient() function\n",
    "    # apply gradient descent now to update a and b\n",
    "    da, db = gradient(x,a,b,y_true)\n",
    "    yp = y(x,a,b)\n",
    "    # updating \n",
    "    a = a-learning_rate * da\n",
    "    b = b-learning_rate * db\n",
    "    l_mse = loss(yp,y_true)                                # calculate loss at this point\n",
    "    loss_mse.append(l_mse)\n",
    "\n",
    "    print(\"Epoch \",i+1,\" Completed!\",\"loss = \",l_mse)\n",
    "  \n",
    "  print(\"Training completed!!\")\n",
    "\n",
    "  assert(a.shape==(n,))\n",
    "\n",
    "  return (loss_mse,a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VsR5XLl_WVu4"
   },
   "source": [
    "### **Training** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5A9mqkqLWU27",
    "outputId": "fbf7262f-9299-492b-fce1-f6763f5c5c3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1  Completed! loss =  421333293468.0863\n",
      "Epoch  2  Completed! loss =  418853998372.9397\n",
      "Epoch  3  Completed! loss =  416403127265.34235\n",
      "Epoch  4  Completed! loss =  413980195388.2227\n",
      "Epoch  5  Completed! loss =  411584727500.5148\n",
      "Epoch  6  Completed! loss =  409216257683.0663\n",
      "Epoch  7  Completed! loss =  406874329148.53656\n",
      "Epoch  8  Completed! loss =  404558494055.2399\n",
      "Epoch  9  Completed! loss =  402268313324.80725\n",
      "Epoch  10  Completed! loss =  400003356463.6204\n",
      "Epoch  11  Completed! loss =  397763201387.9137\n",
      "Epoch  12  Completed! loss =  395547434252.4854\n",
      "Epoch  13  Completed! loss =  393355649282.9323\n",
      "Epoch  14  Completed! loss =  391187448611.3546\n",
      "Epoch  15  Completed! loss =  389042442115.42444\n",
      "Epoch  16  Completed! loss =  386920247260.78925\n",
      "Epoch  17  Completed! loss =  384820488946.7238\n",
      "Epoch  18  Completed! loss =  382742799354.928\n",
      "Epoch  19  Completed! loss =  380686817801.4823\n",
      "Epoch  20  Completed! loss =  378652190591.8201\n",
      "Epoch  21  Completed! loss =  376638570878.6944\n",
      "Epoch  22  Completed! loss =  374645618523.0935\n",
      "Epoch  23  Completed! loss =  372672999957.97156\n",
      "Epoch  24  Completed! loss =  370720388054.83575\n",
      "Epoch  25  Completed! loss =  368787461993.03296\n",
      "Epoch  26  Completed! loss =  366873907131.77057\n",
      "Epoch  27  Completed! loss =  364979414884.73737\n",
      "Epoch  28  Completed! loss =  363103682597.3206\n",
      "Epoch  29  Completed! loss =  361246413426.3532\n",
      "Epoch  30  Completed! loss =  359407316222.3173\n",
      "Epoch  31  Completed! loss =  357586105413.98285\n",
      "Epoch  32  Completed! loss =  355782500895.43085\n",
      "Epoch  33  Completed! loss =  353996227915.37665\n",
      "Epoch  34  Completed! loss =  352227016968.78577\n",
      "Epoch  35  Completed! loss =  350474603690.7154\n",
      "Epoch  36  Completed! loss =  348738728752.3312\n",
      "Epoch  37  Completed! loss =  347019137759.0831\n",
      "Epoch  38  Completed! loss =  345315581150.93713\n",
      "Epoch  39  Completed! loss =  343627814104.69714\n",
      "Epoch  40  Completed! loss =  341955596438.3143\n",
      "Epoch  41  Completed! loss =  340298692517.1668\n",
      "Epoch  42  Completed! loss =  338656871162.26105\n",
      "Epoch  43  Completed! loss =  337029905560.3353\n",
      "Epoch  44  Completed! loss =  335417573175.77167\n",
      "Epoch  45  Completed! loss =  333819655664.3859\n",
      "Epoch  46  Completed! loss =  332235938788.9026\n",
      "Epoch  47  Completed! loss =  330666212336.23914\n",
      "Epoch  48  Completed! loss =  329110270036.4502\n",
      "Epoch  49  Completed! loss =  327567909483.342\n",
      "Epoch  50  Completed! loss =  326038932056.72833\n",
      "Epoch  51  Completed! loss =  324523142846.2613\n",
      "Epoch  52  Completed! loss =  323020350576.8573\n",
      "Epoch  53  Completed! loss =  321530367535.611\n",
      "Epoch  54  Completed! loss =  320053009500.2497\n",
      "Epoch  55  Completed! loss =  318588095669.0355\n",
      "Epoch  56  Completed! loss =  317135448592.09314\n",
      "Epoch  57  Completed! loss =  315694894104.1901\n",
      "Epoch  58  Completed! loss =  314266261258.8414\n",
      "Epoch  59  Completed! loss =  312849382263.7976\n",
      "Epoch  60  Completed! loss =  311444092417.8558\n",
      "Epoch  61  Completed! loss =  310050230048.9464\n",
      "Epoch  62  Completed! loss =  308667636453.52106\n",
      "Epoch  63  Completed! loss =  307296155837.1398\n",
      "Epoch  64  Completed! loss =  305935635256.3102\n",
      "Epoch  65  Completed! loss =  304585924561.5184\n",
      "Epoch  66  Completed! loss =  303246876341.3934\n",
      "Epoch  67  Completed! loss =  301918345868.0515\n",
      "Epoch  68  Completed! loss =  300600191043.5423\n",
      "Epoch  69  Completed! loss =  299292272347.3899\n",
      "Epoch  70  Completed! loss =  297994452785.22394\n",
      "Epoch  71  Completed! loss =  296706597838.4376\n",
      "Epoch  72  Completed! loss =  295428575414.90314\n",
      "Epoch  73  Completed! loss =  294160255800.66187\n",
      "Epoch  74  Completed! loss =  292901511612.6505\n",
      "Epoch  75  Completed! loss =  291652217752.33234\n",
      "Epoch  76  Completed! loss =  290412251360.345\n",
      "Epoch  77  Completed! loss =  289181491772.011\n",
      "Epoch  78  Completed! loss =  287959820473.81305\n",
      "Epoch  79  Completed! loss =  286747121060.70966\n",
      "Epoch  80  Completed! loss =  285543279194.37823\n",
      "Epoch  81  Completed! loss =  284348182562.2445\n",
      "Epoch  82  Completed! loss =  283161720837.4115\n",
      "Epoch  83  Completed! loss =  281983785639.3711\n",
      "Epoch  84  Completed! loss =  280814270495.52277\n",
      "Epoch  85  Completed! loss =  279653070803.4988\n",
      "Epoch  86  Completed! loss =  278500083794.20844\n",
      "Epoch  87  Completed! loss =  277355208495.71173\n",
      "Epoch  88  Completed! loss =  276218345697.7571\n",
      "Epoch  89  Completed! loss =  275089397917.0869\n",
      "Epoch  90  Completed! loss =  273968269363.43542\n",
      "Epoch  91  Completed! loss =  272854865906.2181\n",
      "Epoch  92  Completed! loss =  271749095041.90604\n",
      "Epoch  93  Completed! loss =  270650865862.07605\n",
      "Epoch  94  Completed! loss =  269560089022.07043\n",
      "Epoch  95  Completed! loss =  268476676710.35065\n",
      "Epoch  96  Completed! loss =  267400542618.43622\n",
      "Epoch  97  Completed! loss =  266331601911.46747\n",
      "Epoch  98  Completed! loss =  265269771199.37152\n",
      "Epoch  99  Completed! loss =  264214968508.60754\n",
      "Epoch  100  Completed! loss =  263167113254.49637\n",
      "Training completed!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/psh86dn96ss_b4khvkydrgq80000gn/T/ipykernel_20761/1963601796.py:16: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  da =  (2/m)* np.sum(np.multiply(x,(yp-y_true)[:,np.newaxis]),axis=0)           # write code to calculate derivative of loss with respect to a\n"
     ]
    }
   ],
   "source": [
    "epochs = 100           # tweak this!!!\n",
    "learn_rate = 0.001     # choose learning rate wisely otherwise loss may diverge!!\n",
    "\n",
    "train_loss,a,b= gradient_descent(x_train,y_train,learn_rate,epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDH-7NHQT50f"
   },
   "source": [
    "### **Evaluation and Visualization**\n",
    "Lets plot how loss varies with epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "d7JRB_nJUEkV",
    "outputId": "ddb62e16-1615-41c5-e751-f54abec930f5"
   },
   "outputs": [],
   "source": [
    "test_loss = loss(y(x_train,a,b),y_train)\n",
    "\n",
    "print(\"Loss on test data = \",test_loss)\n",
    "\n",
    "# Visualization of loss\n",
    "\n",
    "plt.plot(epochs,test_loss)                   # plot loss versus epochs\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQ5wPjPb57pb"
   },
   "source": [
    "## **Deep Learning**\n",
    "In this section We will build a simple multilayer perceptron network(**MLP**) in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EGoZEKIbdXZD"
   },
   "outputs": [],
   "source": [
    "# Lets import the required libraries\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThuZ51gEdXZF"
   },
   "source": [
    "### **Load Dataset**\n",
    "We will be using MNIST dataset of handwritten digits\n",
    "\n",
    "Just run the cell below to load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xj3J8Dp-dXZG",
    "outputId": "d77e8fb0-a9bc-4114-e41b-373550bc5416"
   },
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(\"No. of training examples = \",x_train.shape[0])\n",
    "print(\"Size of each image in dataset = \",x_train.shape[1:])\n",
    "print(\"No. of test examples = \",x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "XX9xW4ardXZG",
    "outputId": "a8261aec-d3de-44c6-876d-4788758754ff"
   },
   "outputs": [],
   "source": [
    "# Run this cell to visualize some of the images from dataset\n",
    "\n",
    "n = 5    # = no. of images to visualize\n",
    "\n",
    "index = np.random.choice(x_train.shape[0],5)  # choose random index\n",
    "print(\"label: \",end=\"\")\n",
    "\n",
    "for i,ind in enumerate(index):\n",
    "    plt.subplot(1,n,i+1)\n",
    "    plt.imshow(x_train[ind],cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    print(y_train[ind],end=\"       \")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQcA9i9YdXZH"
   },
   "source": [
    "#### Preprocess dataset\n",
    "Since we are building a MLP model the input to the model should be a vector rather than a 28 by 28 matrix.\n",
    "\n",
    "So your **First Task** is to flatten the images\n",
    "\n",
    "(Hint: use *reshape()* method of arrays...)\n",
    "\n",
    "Next, create validation dataset out of training dataset.\n",
    "\n",
    "You can use 50K images for training and 10K for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RXnkfE6gdXZI"
   },
   "outputs": [],
   "source": [
    "# Flatten the images into 1-d vectors\n",
    "\n",
    "x_train_flatten = x_train.reshape((x_train.shape[0], 28, 28, 1))                               # flatten the images of training set \n",
    "x_test_flatten = x_test.reshape((x_test.shape[0], 28, 28, 1))                                        # flatten th eimages of test set\n",
    "\n",
    "\n",
    "# Divide the training data into training and validation data....\n",
    "\n",
    "n_validation = 10000                                        # choose number of images to be used for validation\n",
    "\n",
    "x_validation = 50000\n",
    "y_validation = 10000\n",
    "\n",
    "x_train_flatten = \n",
    "y_train = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMGl2aq3dXZJ"
   },
   "source": [
    "### **Build a model**\n",
    "You can choose whatever architechure you want, but ensure that it is **not too deep** as that will take too much time to train and **not too shallow** as that will give very low accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A7yr3nwTdXZK"
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    ...\n",
    "])\n",
    "\n",
    "# Make a graphical representation of the model...\n",
    "keras.utils.plot_model(model,show_shapes=True)\n",
    "model.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7oDNvKB6dXZL"
   },
   "source": [
    "#### Compile and Train\n",
    "Choose an optimizer- method that minimizes loss function\n",
    "\n",
    "**adam** optimizer is one of the popular choices. You should read about these online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7DM9i_F5dXZL"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"...\",loss = \"...\",metrics=[\"accuracy\"])\n",
    "\n",
    "n_epochs = ...              # set number of epochs\n",
    "batch_size = 512            # you can tweak with these parametrs\n",
    "history = model.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QTWTtoVdXZM"
   },
   "source": [
    "### **Evaluate**\n",
    "Evaluate your model on test data.\n",
    "\n",
    "And Show some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bhuBGWg-dXZM"
   },
   "outputs": [],
   "source": [
    "results = model.evaluate(...)\n",
    "print(\"Loss = \",results[0])\n",
    "print(\"Accuracy = \",results[1]*100,\"%\")\n",
    "\n",
    "# Plot Accuracy...\n",
    "plt.plot(..., label=\"Training accuracy\")\n",
    "plt.plot(..., label=\"validation Accuracy\")\n",
    "plt.title(\"Model accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Similarly write code to plot loss...\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Hjr0CBhdXZN"
   },
   "source": [
    "Lets show our results on images from testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sEs1cVAHdXZN"
   },
   "outputs": [],
   "source": [
    "n = ...   # = no. of images to see predictions on\n",
    "\n",
    "index = np.random.choice(...)  # choose random index from test data\n",
    "print(\"label: \")\n",
    "\n",
    "for i,ind in enumerate(index):\n",
    "    plt.subplot(1,n,i+1)\n",
    "    plt.imshow(...)             # fill code to show images from test set\n",
    "    plt.axis(\"off\")\n",
    "    print(y_test[ind],end=\"       \")\n",
    "\n",
    "plt.show()\n",
    "print(\"Predicted value: \")\n",
    "\n",
    "# Now lets print the predictions\n",
    "\n",
    "for i,ind in enumerate(index):\n",
    "    # write code to predict and print digit in image\n",
    "    # Hint: the output of the model is a 10-d vector which gives probabilties\n",
    "    # The digit in the image would be the class for which probability is hghest...\n",
    "\n",
    "    digit = ...\n",
    "    print(digit,end=\"      \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ne8-aBvHdXZO"
   },
   "source": [
    "That's it you have completed the assignment !!\n",
    "\n",
    "We hope that you learned something from this exercise\n",
    "\n",
    "### Credits:\n",
    "\n",
    "**Leaders:**\n",
    "\n",
    "Mohit Kulkarni\n",
    "\n",
    "Shivanshu Tyagi\n",
    "\n",
    "**Scretaries:**\n",
    "\n",
    "Sahil Bansal\n",
    "\n",
    "Shashwat Gupta\n",
    "\n",
    "Rashmi Sharma"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
